
# 1、 绪论

科学：是什么，为什么
技术：怎么做
工程：做的多快好省
应用

# 2、基本术语
经典定义：利用经验改善系统自身性能

![image.png](https://yancey-note-img.oss-cn-beijing.aliyuncs.com/20250303134800.png)

# 3、归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好，任何一个有效的机器学习算法必有其偏好
一般原则：奥卡姆剃刀 -> 若非必要，勿增实体

# 4、NFL定理

NFL定理：一个算法若在某些问题上a比另一个算法b好，必然存在另一些问题，b比a好

# 5、泛化误差和经验误差

泛化误差：在未来样本上的误差
经验误差：在训练集上的误差，也叫训练误差

经验误差不是越小越好，可能会出现过拟合和欠拟合
![image.png](https://yancey-note-img.oss-cn-beijing.aliyuncs.com/20250303141225.png)



# 6、三个关键问题


如何获得测试结果？ 评估方法
如何评估性能优劣？ 性能度量
如何判断实质差别？ 比较检验

# 7、评估方法

关键：怎么获得测试集。测试集应该与训练集互斥

常见方法：
1、留出法
保持数据分布的一致性（分层采样）
多次重复划分
测试集不能太大，也不能太小
2、交叉检验法
3、自助法

# 8、调参与验证集

算法的参数：一般由人工设定，也称“超参数”
模型的参数：一般由学习确定
调参过程相似：先产生若干模型，然后基于某种评估方法进行选择

验证集：可用于模型调参
算法选定后，要用训练集+验证集重新训练最终模型

# 9、性能度量
性能度量是衡量模型泛化能力的评价标准，反映了任务需求。使用不同的性能度量往往会导致不同的评判结果

什么样的模型好，不仅取决于算法和数据，还取决于任务需求
错误率 、精度

![image.png](https://yancey-note-img.oss-cn-beijing.aliyuncs.com/20250303163036.png)



查准率：P =TP/(TP+FP)
查全率：R = TP/(TP+FN)
F1：
![image.png](https://yancey-note-img.oss-cn-beijing.aliyuncs.com/20250303163600.png)

# 10、比较检验

