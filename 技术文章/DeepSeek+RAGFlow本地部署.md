
# 1、基本概念
我们的需求：绝对的隐私保护和个性化知识库构建
场景：比如如果你希望大模型能根据你们企业的规章制度来回答问题，那么首先你肯定需要将这些规章制度或者模型作为附件上传，但你仍然可能面临一些别的1、直接使用网页AI对话模型问题：
- 一个是数据隐私问题；联网使用大模型，所有数据均会上传到DeepSeek服务器，数据隐私性无法得到保证；
- 第二个是上传文件的限制问题；一般来说网页版AI对于文件上传数量是有限制的，因为解析附件需要额外的算力；即使你是付费用户，有时你想要上传的文件不是一个两个，而是几百个文件，也就是一个专业领域的知识库，模型同样可能无力支持；
- 第三个问题是上传文件附件方式使用起来繁琐：仅仅只是将文件作为附件加入对话上下文，每一次想要让模型根据这些附件回答问题的时候，都需要重新上传附件；想要新增、删除、修改已有的附件，同样也是很难实现的；

2、解决：
（1）隐私保护
- 通过对话大模型（如DeepSeek）的本地部署解决隐私问题；

（2）个性化知识库构建
使用RAG技术（Retrieval-Augmented Generation，检索增强生成）构建个人知识库。为此我们需要：
- 本地部署RAG技术所需要的开源框架RAGFlow；
- 本地部署Embedding大模型（或者直接部署自带Embedding模型的RAGFlow版本）；

# 2、RAG和模型微调的区别

大模型不知道你的这些私有知识，当它回答自己不知道的问题时会出现“幻觉”问题；
微调技术和RAG技术的区别：
微调：在已有的预训练模型基础上，再结合特定任务的数据集进一步对其进行训练，使得模型在这一领域中表现更好（微调是考前复习，模型通过训练，消化吸收了这些知识然后给你回复）；
RAG：在生成回答之前，通过信息检索从外部知识库中查找与问题相关的知识，增强生成过程中的信息来源，从而提升生成的质量和准确性。（RAG是开卷考试，模型看到你的问题，开始翻你的知识库，以实时生成更准确的答案）；
RAG（Retrieval-Augmented Generation）技术原理：
检索（Retrieval）：当用户提出问题时，系统会从外部的知识库中检索出与用户输入相关的内容。
增强（Augmentation）：系统将检索到的信息与用户的输入结合，扩展模型的上下文。这让生成模型（也就是Deepseek）可以利用外部知识，使生成的答案更准确和丰富。
生成（Generation）：生成模型基于增强后的输入生成最终的回答。它结合用户输入和检索到的信息，生成符合逻辑、准确且可读的文本内容。
